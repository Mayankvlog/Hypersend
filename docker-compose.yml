services:
  nginx:
    image: nginx:alpine
    container_name: hypersend_nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro
      - nginx_cache:/var/cache/nginx
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      - backend
      - websocket
      - worker
    networks:
      - hypersend_network
    healthcheck:
      test: ["CMD", "sh", "-c", "curl -f -s http://127.0.0.1/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    environment:
      - NGINX_ALLOW_UNSAFE=true
      - NGINX_API_BASE_URL=${API_BASE_URL:-https://zaply.in.net/api/v1}
      - NGINX_API_HOST=${API_HOST:-0.0.0.0}
      - NGINX_API_KEY=${API_KEY:-hypersend_secure_api_key}
      - NGINX_API_SECRET=${API_SECRET:-hypersend_secure_api_secret}
      # WhatsApp-grade timeouts
      - NGINX_PROXY_READ_TIMEOUT=7200  # 2 hours for large file downloads
      - NGINX_PROXY_SEND_TIMEOUT=7200  # 2 hours for large file uploads
      - NGINX_PROXY_CONNECT_TIMEOUT=600  # 10 minutes for backend connection
      - NGINX_CLIENT_BODY_TIMEOUT=7200  # 2 hours for client body upload
      - NGINX_CLIENT_MAX_BODY_SIZE=15G  # Allow 15GB files
      - NGINX_REQUEST_TIMEOUT=7200  # 2 hours request timeout
      - NGINX_SEND_TIMEOUT=7200  # 2 hours send timeout
      - NGINX_READ_TIMEOUT=7200  # 2 hours read timeout
      # Enhanced error handling configuration
      - NGINX_ERROR_PAGE_TIMEOUT=30  # Error page timeout
      - NGINX_MAX_RETRIES=7  # Maximum retry attempts
      - NGINX_RETRY_DELAY=5  # Delay between retries
      # Production domain configuration
      - DOMAIN_NAME=zaply.in.net
      - SSL_CERT_PATH=/etc/nginx/ssl/zaply.in.net/fullchain.pem
      - SSL_KEY_PATH=/etc/nginx/ssl/zaply.in.net/privkey.pem

  # WhatsApp-style Backend API (Stateless, Horizontal Scaling)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: hypersend_backend
    restart: unless-stopped
    environment:
      # WhatsApp-grade environment
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-change_this_password_in_prod}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongodb:27017/hypersend}
      - JWT_SECRET=${JWT_SECRET:-your_jwt_secret_here}
      - ENVIRONMENT=production
      # WhatsApp security settings
      - ENABLE_E2EE=true
      - MAX_FILE_SIZE=16106127360  # 15GB in bytes
      - MEDIA_TTL=86400  # 24 hours
      - MESSAGE_TTL=86400  # 24 hours
      - DEVICE_SESSION_TIMEOUT=604800  # 7 days
      # Rate limiting (WhatsApp-grade)
      - RATE_LIMIT_REQUESTS=1000
      - RATE_LIMIT_WINDOW=60
      # Logging and monitoring
      - LOG_LEVEL=INFO
      - ENABLE_METRICS=true
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - hypersend_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      replicas: 3  # WhatsApp-style horizontal scaling
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.25'
    # CRITICAL: No volume mounts (stateless)
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # WhatsApp-style WebSocket Service (High Concurrency)
  websocket:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: hypersend_websocket
    restart: unless-stopped
    command: ["python", "-m", "uvicorn", "backend.websocket:app", "--host", "0.0.0.0", "--port", "8001"]
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-change_this_password_in_prod}
      - ENVIRONMENT=production
      # WebSocket-specific settings
      - WEBSOCKET_HEARTBEAT_INTERVAL=30
      - WEBSOCKET_MAX_CONNECTIONS=10000
      - WEBSOCKET_PING_TIMEOUT=60
      - WEBSOCKET_CLOSE_TIMEOUT=300
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - hypersend_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      replicas: 5  # More replicas for WebSocket scaling
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.1'
    # CRITICAL: No volume mounts (stateless)
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # WhatsApp-style Background Workers (Media Cleanup, ACK Reconciliation)
  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: hypersend_worker
    restart: unless-stopped
    command: ["python", "-m", "celery", "worker", "-A", "backend.celery_app", "--loglevel=info", "--concurrency=4"]
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-change_this_password_in_prod}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongodb:27017/hypersend}
      - ENVIRONMENT=production
      # Worker-specific settings
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - WORKER_CONCURRENCY=4
      - WORKER_PREFETCH_MULTIPLIER=1
      - WORKER_MAX_TASKS_PER_CHILD=1000
      # WhatsApp cleanup settings
      - MEDIA_CLEANUP_INTERVAL=300  # 5 minutes
      - MESSAGE_CLEANUP_INTERVAL=600  # 10 minutes
      - ACK_RECONCILIATION_INTERVAL=180  # 3 minutes
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - hypersend_network
    deploy:
      replicas: 2  # Background workers for high throughput
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.1'
    # CRITICAL: No volume mounts (stateless)
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
    image: redis:7-alpine
    container_name: hypersend_redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    # WHATSAPP ARCHITECTURE: Messages stored in Redis with automatic TTL expiry
    # MANDATORY SETTINGS:
    # - --appendonly no: Disable .aof persistence file
    # - NO --save: Disable RDB snapshots
    # - --maxmemory 2gb: Limit memory to 2GB for ephemeral messages
    # - --maxmemory-policy allkeys-lru: Evict oldest messages when full
    # - --requirepass: Authentication password
    # RESULT: Messages lost on restart (ACCEPTABLE - user device has backup)
    command: >
      redis-server
      --port 6379
      --bind 0.0.0.0
      --appendonly no
      --save ""
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD:-change_this_password_in_prod}
      --tcp-backlog 65535
      --timeout 0
      --tcp-keepalive 300
      --loglevel notice
    networks:
      - hypersend_network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-change_this_password_in_prod}", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    sysctls:
      - net.core.somaxconn=65535
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD:-change_this_password_in_prod}

  minio:
    image: minio/minio:latest
    container_name: hypersend_minio
    restart: unless-stopped
    ports:
      - "9000:9000"
      - "9001:9001"  # MinIO Admin Console
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-change_this_password_in_prod}
      MINIO_REGION: ${AWS_REGION:-us-east-1}
    command: server /minio_data --console-address ":9001"
    volumes:
      - minio_data:/minio_data
    networks:
      - hypersend_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    sysctls:
      - net.core.somaxconn=65535

  frontend:
    image: yourusername/hypersend-frontend:latest
    container_name: hypersend_frontend
    restart: unless-stopped
    ports:
      - "3000:80"
    depends_on:
      api:
        condition: service_healthy
    networks:
      - hypersend_network
    healthcheck:
      test: ["CMD", "sh", "-c", "curl -f -s http://127.0.0.1/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  hypersend_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  # WHATSAPP ARCHITECTURE: nginx_cache is ephemeral (not permanent data)
  # - Cache cleared on container restart (acceptable)
  # - NOT used for media or messages
  # - Only for static frontend assets
  # - In Kubernetes, this maps to emptyDir with memory tmpfs
  nginx_cache:
    driver: local
  
  # MinIO data storage (encrypted blobs only, client-side E2EE)
  # - Server never sees plaintext
  # - Each file encrypted by sender before upload
  # - Auto-delete after 24h TTL (lifecycle policy)
  minio_data:
    driver: local